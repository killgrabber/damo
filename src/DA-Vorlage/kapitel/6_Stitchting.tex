
\chapter{Stitching}

Für jeden Einspannzustand eines Bauteils können mehrere Bilddateien vorliegen.
Alle Bilddateien gehören zu dem gleichen Bauteil und müssen 
zusammengefügt werden, um ein einzelnes Bild zu erhalten. 
Als Voraussetzung ist gegeben, dass alle Bilder Überlappungen enthalten.

Diese Überlappung kann benutzt werden, um die Bilder zu einem Bild zusammenzufügen.
Für das Stitching von Bilddateien existieren schon mehrere Verfahren, die in Bibliotheken
für viele Programmiersprachen implementiert sind. Der schon beschriebene 
ICP-Algorithmus~\ref{icp}
ist eines dieser Verfahren. Das Problem mit diesen Verfahren ist, dass zwei 
Datensätze registriert werden, indem auf ein Datensatz so lange eine 
Transformation (vgl.~\ref*{Transformation}) angewendet wird, bis
die Distanz der Datensätze unter einen Grenzwert fällt oder nicht mehr verbessert
werden kann. Die Überlappung in den von dem Laserscanner aufgenommen Daten ist jedoch 
nur in zwei Achsen verschoben. Durch eine Rotation kann eine Transformation 
berechnet werden, die nicht der Realität entspricht, gesucht ist eine Transformation 
die ausschließlich aus einer Translation in zwei Achsen besteht.

Um die korrekte Transformation zu finden, mit der die beiden Bilder überlappen,
muss nicht der komplette Bereich analysiert werden, sondern nur der überlappende Teil.

In diesem Bildausschnitt müssen gemeinsame Bereiche in beiden Bildern erkannt werden. 
Diese gemeinsamen Bereiche können anschließend miteinander verglichen werden.
Bereiche, die verglichen werden können, sind Ränder oder Farbunterschiede im Bild 
und werden im folgenden als Features bezeichnet.

\section{Feature Erkennung} \label{contoursearching}

Features in einem Bild sind große Unterschiede in benachbarten Pixeln. Die größten
Features sind die Ränder des Bauteils, kleinere Features können Oberflächenänderungen 
oder Spuren des Herstellungsprozesses sein. Diese Unterschiede können mithilfe 
der 'OpenCV' Bibliothek extrahiert werden. Diese Bibliothek gibt die erkannten 
Features als Liste von Konturen aus. Konturen selbst bestehen aus Listen von 
Punkten, die aus X und Y Koordinaten bestehen. Die Konturerkennung kann verbessert 
werden, indem das Bild entsprechend präpariert wird. In Abbildung~\ref{fig:cons} und
~\ref{fig:image_top} ist ein Ursprungsbild und die extrahierten Konturen zu sehen.
Trotz intensiver vorheriger Filterung sind in Abbildung~\ref{fig:cons} immer noch 
Messfehler in den Konturen zu sehen. Diese müssen entfernt werden, damit die Bilder 
korrekt zusammengefügt werden können. Erfolgt dies nicht werden diese Fehler miteinander
verglichen, was das Ergebnis verfälscht.
Die fehlerhaften Konturen können über die Länge der Kontur entfernt werden. Es werden 
nur Konturen weiter betrachtet die aus mehr als 100 Punkten bestehen. Zusätzlich werden 
Punkte in Konturen entfernt, die zu nah am Bildrand liegen. Dadurch wird verhindert, 
dass der Bildrand als Kontur erkannt wird.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/fdm_top_10p.png} % first figure itself
    \caption{Oberes Bild eines Scanvorgangs, FDM Bauteil}
    \label{fig:image_top}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/contours_of_image.png} % second figure itself
    \caption{Extrahierte Konturen des Bildes ohne vorherige Filterung, 
    der überlappende Bereich ist rot markiert.}
    \label{fig:cons}
\end{figure}

Die Überlappung kann aufgrund des Prozesses der Datenaufnahme, 
nur im oberen oder unteren Bildbereich auftreten. Wenn das Bild 
aus dem ersten Scan eines Bauteils kommt, ist der überlappende Bereich am 
oberen Bildrand, anderenfalls am unteren. 
Der Teil des Bildes, der keine Überlappung enthält, wird nicht weiter betrachtet. 
Hierdurch wird Rechenzeit gespart.

Durch wiederholtes Durchführen des Stitching Verfahrens können beliebig viele Bilder, 
die Überlappungen enthalten, zusammengefügt werden. In jeder Wiederholung werden genau
zwei Bilder zusammengefügt, das resultierende Bild kann dann wieder mit dem
nächsten Bild zusammengeführt werden. Aus diesem Grund beschreibt der folgende 
Teil die Methode bezogen auf zwei Bilder.

Beide Bilder werden auf den überlappenden Bereich zugeschnitten. 
Anschließend werden in diesem Bereich Konturen extrahiert. 
Würden beide Bildteile vollständig überlappen, könnte jetzt der ICP-Algorithmus
angewendet werden. Dieser würde dann die korrekte Transformation berechnen, in 
die Konturen aus dem oberen Bild, mit denen aus dem unteren Bild verglichen werden
und die Distanz zwischen den Punkten minimiert wird. 
Der Grad der Überlappung ist unbekannt und kann nicht im Vorhinein bestimmt werden.
Dadurch kann der ICP-Algorithmus nicht eingesetzt werden. 
Eine andere wichtige Annahme kann getroffen werden: Jeweils eine Kontur aus 
dem oberen und unteren Bild haben mindestens einen gemeinsamen Punkt.

\section{Differenzierung von Punkten}

Die Distanz zwischen zwei Punkten kann über den euklidischen Abstand gemessen werden
~\cite{Dokmanic.2015}. Sei A ein Punkt in einer Kontur aus dem oberen Bild und K eine 
Kontur aus dem unteren Bild.  
Um den Punkt aus K zu finden, der am nächsten an A liegt, muss A mit jedem Punkt aus 
K verglichen werden. Das Punktepaar mit dem kleinsten gefunden euklidischen Abstand 
wird als \glq Best Match\grq gespeichert. Wenn die euklidische Distanz null beträgt, kann 
die Suche abgebrochen werden, da kein kleinerer Wert mehr gefunden werden kann.
Dieser Ansatz ist dem ICP-Algorithmus ähnlich. Die Differenz zwischen zwei Konturen 
K1 und K2 kann verglichen werden, indem für jeden Punkt A aus K1 der näheste Punkt aus 
K2 gefunden wird. In dem ICP-Algorithmus werden alle Distanzen von der \glq Best Matches \grq 
aufsummiert und beschreiben den Unterschied der beiden Distanzen. Diese Summe kann dann 
minimiert werden. Dieser Ansatz funktioniert bei einem sich nur partiell
überlappenden Datensatz nicht. 
Statt die Summe zu bilden, wird jede beste Distanz zusammen mit ihren korrespondieren 
Punkten gespeichert. Um den Grad der Überlappung zu bestimmen, werden die Distanzen 
gezählt die gleich null sind. Dieser Wert in Relation zu der Länge von K1 gibt, 
in Prozent, an zu welchem Anteil sich die beiden Konturen überlappen.

\section{Transformation bestimmen}

Gesucht ist die Transformation welche die maximale Überlappung der beiden 
Konturen K1 und K2 bietet. Um diese Transformation zu berechnen, muss der 
Grad der Überlappung für jede mögliche Positionierung ermittelt werden. Jeder
Punkt aus K2 muss auf die Koordinaten eines beliebigen aber festen Punkts aus K1 
verschoben werden.
Die Transformation zwischen zwei Punkten A und B kann über die Vektorberechnung erfolgen:

\begin{equation*}
    T_{a,b} = \begin{pmatrix}a_x\\a_y\end{pmatrix} - \begin{pmatrix}b_x\\b_y\end{pmatrix}
\end{equation*}

Kontur K2 kann über Kontur K1 verschoben werden, indem Punkt A festgehalten wird, 
während Punkt B sukzessive jeden Punkt aus K2 annimmt. 
Die daraus resultierende Punkttransformation wird auf jeden Punkt von K1 angewendet, 
um die nächstgelegenen Nachbarpunkte zu ermitteln. Für jede Transformation wird der 
Überlappungsanteil berechnet, wobei das Ergebnis mit der maximalen Überlappung
als die optimale Transformation gespeichert wird.
Dieses Verfahren ist nur anwendbar, wenn Punkt A im überlappenden Bereich liegt. 
Befindet sich Punkt A nicht in der Kontur K2, 
kann das Verfahren nicht erfolgreich angewendet werden.
Zur Berechnung der optimalen Transformation werden verschiedene Punkte aus K1 
ausgewählt und das Verfahren jeweils angewendet. 
Die Transformation mit dem größten Verhältnis von Nullen zur
Gesamtlänge der Kontur wird als optimal angesehen. 
Aufgrund des exponentiellen Laufzeitverhaltens ist es ineffizient, 
jeden Punkt A aus K1 mit jedem Punkt B aus K2 zu vergleichen.

In Abbildung~\ref{fig:k1_and_k2} (a) sind zwei Beispielkonturen zu sehen. 
Diese sind nicht angeordnet. Der ICP-Algorithmus würde diese beiden Konturen 
annähern, ohne sie zu überlappen. 
Das Ergebnis des vorgestellten Stitching Verfahrens ist in Abbildung 
~\ref{fig:k1_and_k2} (b) zu sehen. Es ist zu erkennen das, trotz Messfehler und 
kleineren unterschieden im überlappenden Bereich die korrekte Transformation 
ermittelt werden konnte. Diese Konturen stammen von einem additiv gefertigten 
Metallbauteil.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/before_matching.png} % first figure itself
        \caption*{(a)} 
    \end{minipage}\hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/0.24225865209471767contours.png} % first figure itself
        \caption*{(b)}
    \end{minipage}\hfill
    \caption{(a) Konturen K1 und K2 so positioniert wie sie in den
    Ursprungsbildern gefunden wurde.
    (b) Konturen, transformiert mit größter Überlappung, 
        Grad der Überlappung: 24,26 \%}
        \label{fig:k1_and_k2}
\end{figure}

\section{Visuelle Darstellung des Stitching Prozesses}

In Abbildung~\ref{fig:stitching_all} ist der Prozess des Verfahrens zu sehen.
K1 ist in blau dargestellt, K2 in grün.
In jeden Bild ist der Grad der Überlappung dargestellt. Es ist dargestellt, wie
Kontur K2 über K1 geschoben wird, um den besten Grad der Übereinstimmung zu ermitteln.
Die Bilder sind repräsentativ ausgewählt, im tatsächlichen Prozess wird K1 komplett 
über K2 bewegt.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/stitching_beginn.PNG} % first figure itself
        \caption*{(a)}
    \end{minipage}\hfill
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/stitching_middle.PNG} % first figure itself
        \caption*{(b)}
    \end{minipage}\hfill
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/stitching_match.PNG} % first figure itself
        \caption*{(c)}
    \end{minipage}\hfill
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/stitching_end.PNG} % first figure itself
        \caption*{(d)}
    \end{minipage}\hfill
    \caption{Verfahren im Verlauf dargestellt, a zu Beginn, b nach n-durchgängen, c }
    bei einem guten Match, d Kontur K2 komplett über K1 geschoben, 
    am Ende der Durchgänge.
    \label{fig:stitching_all}
\end{figure}

\section{Bilder zusammenfügen}

Nachdem alle Transformationen vorliegen wird die Transformation mit der besten 
Übereinstimmung gewählt. Diese wird genutzt, um die beiden Bilder zusammenzufügen.
Das zugehörige Bild der Konturen K2 wird transformiert, indem die Transformation 
auf jeden Pixel angewendet wird.  
Die Transformation ist nur korrekt, wenn die beiden Bilder die gleichen 
Ursprungskoordinaten haben, die auch bei den Konturen K1 und K2 verwendet wurden.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/AM_SP0_stitched_2.png} % first figure itself
    \caption{Zusammengefügtes Bild}
    \label{fig:stitched_image}
\end{figure}

\section{Probleme und Lösungen im Verfahren}

Durch die Funktionsweise treten am Randbereich der Scandaten vermehrt Messfehler auf, 
die nicht vollständig durch vorheriges Filtern entfernt werden können. 
Damit diese Messfehler das Stitching nicht verfälschen, werden alle Konturen nochmals 
gefiltert. Alle Punkte in einer Kontur, die sich in einem konfigurierbaren 
Abstand zu den Bildrändern befinden, werden entfernt. Dadurch werden sie bei der 
Berechnung der Transformation nicht verwendet. 
Der konfigurierbare Abstand muss beim Stitching des finalen Bilds berücksichtigt 
werden und von der Transformation abgezogen werden.

Wenn Konturen mit einem großen Längenunterschied verglichen werden, 
kann eine sehr hohe Übereinstimmung ermittelt werden, die aber keine 
tatsächliche Übereinstimmung ist. Dies liegt daran, dass es wahrscheinlicher ist 
eine Sequenz mit fünf Pixeln in einer anderen Sequenz mit 500 Pixeln zu finden.  
Das kann zum Beispiel vorkommen, wenn Konturen 
die am linken und rechten Bildrand in Abbildung \ref{fig:cons} zu sehen sind, 
verglichen werden. Um dies zu vermeiden wird eine Bedienung eingeführt, dass die Länge
der Konturen nicht zu sehr voneinander abweichen darf. Bei einer Abweichung von mehr als
200 Punkten in einer Kontur sollte die Konturen nicht miteinander verglichen werden.

Auch Konturen mit einer Länge von weniger als 100 Punkten sollten nicht berücksichtigt 
werden. Diese beschreiben keine Features in einem Bild, die für das Stitching verwendet 
werden sollten. Diese Konturen beschreiben meist nur Messfehler oder 
Oberflächenstrukturen, die nicht konsistent in beiden Bildern von dem Scanner erkannt 
werden können.

Um das Ergebnis noch weiter zu verbessern, können zwei Konturen zweimal miteinander 
verglichen werden. Während des zweiten Vergleichs wird die Zielkontur mit der 
Ursprungskontur vertauscht. So wird aus beiden Konturen jeweils einmal ein fester 
Punkt gewählt. Wieder wird die Transformation gespeichert mit der besten Überlappung.
Wenn die Überlappung im zweiten Vergleich eine höhere Übereinstimmung hat, muss die 
berechnete Transformation invertiert werden. Geschieht dies nicht, kann die 
Transformation nicht für den finalen Stitchprozess eingesetzt werden, weil dort 
das Ziel und Ursprungsbild fest gesetzt ist.
